
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Methods &mdash; Jubatus</title>
    <link rel="stylesheet" href="_static/jubatus.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

    
<script type="text/javascript">
   var GuideSentence = 'keyword';
   function ShowFormGuide(obj) {
      if( obj.value == '' ) {
         obj.value = GuideSentence;
         obj.style.color = '#cccccc';
      }else{
         obj.style.color = '#333333';
      }
   }
   function HideFormGuide(obj) {
      obj.style.color = '#827046';
      if( obj.value == GuideSentence ) {
         obj.value='';   
      }
   }
</script>
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.9.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Jubatus" href="index.html" />
    <link rel="up" title="Client API" href="api.html" />
    <link rel="next" title="Unlearner" href="api_unlearner.html" />
    <link rel="prev" title="Weight" href="api_weight.html" /> 

<!--

   _________         ___
   \____   _|       | /             ___I_I___
       |  |         | |             \__^ ^__/        ____
       |  |         | | ___    ___  __ | |          / __/
       |  | |-|  |-|| |/   \  /   \| | | | |^|  |^|| (__
       |  | | |  | ||    ^  ||  ^    | | | | |  | | \__ \
       |  | | \_/  ||    O   || O    | | |_| \_/  | ___) |
       |  |  \__/|_||_|\___/  \___/|_| |__/ \__/|_| \___/
       | /
      / /
     |/

-->
  <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26408953-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

  </script>
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="rb-modindex.html" title="Ruby Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="api_unlearner.html" title="Unlearner"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="api_weight.html" title="Weight"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Jubatus</a> &raquo;</li>
          <li><a href="references.html" >References</a> &raquo;</li>
          <li><a href="api.html" accesskey="U">Client API</a> &raquo;</li> 
      </ul>
    </div>
          
		<a href="index.html">
			 <div class="title"></div>
		</a>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Methods</a></li>
<li><a class="reference internal" href="#classifier-regression">Classifier &amp; Regression</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#passive-aggressive">Passive Aggressive</a></li>
<li><a class="reference internal" href="#iterative-parameter-mixture">Iterative Parameter Mixture</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li><a class="reference internal" href="#recommender">Recommender</a><ul>
<li><a class="reference internal" href="#id6">Overview</a></li>
<li><a class="reference internal" href="#data-representation">Data Representation</a></li>
<li><a class="reference internal" href="#similarity-calculation">Similarity Calculation</a></li>
<li><a class="reference internal" href="#algorithms">Algorithms</a><ul>
<li><a class="reference internal" href="#inverted-index">inverted_index</a></li>
<li><a class="reference internal" href="#lsh">lsh</a></li>
<li><a class="reference internal" href="#minhash">minhash</a></li>
<li><a class="reference internal" href="#euclid-lsh">euclid_lsh</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id12">References</a></li>
<li><a class="reference internal" href="#storage">Storage</a><ul>
<li><a class="reference internal" href="#inverted-index-storage">inverted_index_storage</a></li>
<li><a class="reference internal" href="#bit-index-stroage">bit_index_stroage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-distribution">Data Distribution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#anomaly">Anomaly</a><ul>
<li><a class="reference internal" href="#id13">References</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="api_weight.html"
                        title="previous chapter">Weight</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="api_unlearner.html"
                        title="next chapter">Unlearner</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/method.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
          <div id="searchbox" style="display: none">
            <h3>Quick Search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" class="keyword" value="keyword" onFocus="HideFormGuide(this);" onBlur="ShowFormGuide(this);" />
                <input type="submit" value="Go" class="searchBtn" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
	  
          

<a class="twitter-timeline" data-dnt="true" href="https://twitter.com/JubatusOfficial"  data-widget-id="258379257628196864">Tweets by @JubatusOfficial</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="methods">
<h1>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h1>
<p>In this page, we discuss the details of algorithms used in each server. This page is currently written in Japanese; see References section for the list of references for each algorithms.</p>
</div>
<div class="section" id="classifier-regression">
<h1>Classifier &amp; Regression<a class="headerlink" href="#classifier-regression" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>回帰問題は，入力 <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> に対応する特徴ベクトル <img class="math" src="_images/math/9e420ecc16bd5ac5ce4b505f498307f3a6a03514.png" alt="\phi(x) \in R^m"/> に対して，実数値の出力 <img class="math" src="_images/math/c2eda94ebbc667b17e33908ad513ddaf05690612.png" alt="y \in R"/> を当てる問題である．
今回実装したのは，線形回帰モデルである．
線形回帰モデルでは，パラメータ <img class="math" src="_images/math/bd9681d98297d9db0464cdeab0db36faf8550020.png" alt="w \in R^m"/> を利用して，入力 <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> に対して <img class="math" src="_images/math/9a5f43e6b442dc3fd05894c8a36d1be82bf75ec6.png" alt="\hat{y} = w^T \phi(x) \in R"/> で予測する．</p>
<p>学習時には，分類問題同様，正解データセット <img class="math" src="_images/math/d81a01edb74ca9d82c10633854469cc58a99072e.png" alt="\{(x_i, y_i)\}"/> を利用して，正解データに対して正しく予測できるように重みベクトルを推定する．
典型的には1800年代に，予測値と実測値との自乗和を最小化させる最小二乗法が提案されている．
この方法はバッチ処理になるため，今回の調査ではオンライン学習させる方法を利用した．</p>
</div>
<div class="section" id="passive-aggressive">
<h2>Passive Aggressive<a class="headerlink" href="#passive-aggressive" title="Permalink to this headline">¶</a></h2>
<p>Passive Aggressive (PA) <a class="reference internal" href="#crammer03a" id="id1">[Crammer03a]</a> <a class="reference internal" href="#crammer03b" id="id2">[Crammer03b]</a> <a class="reference internal" href="#crammer06" id="id3">[Crammer06]</a> は，Support Vector Regression (SVR) のオンライン版であり，同名の分類器を回帰問題に適用したアルゴリズムである．
PA は， (1) 現在の学習データが与えられた許容範囲 <img class="math" src="_images/math/6fb5df65c0e50c760e7c6462248d06b98eef7c43.png" alt="epsilon"/> 以下で予測する． (2) 分類問題の PA 同様，できる限り現在のパラメータと近い点を選ぶ，という二つの条件を満たすパラメータに更新する．
すなわち， <img class="math" src="_images/math/19bc0073dde1bcd1a8e6a32b251e80cced668f04.png" alt="\epsilon"/> -intensive hinge loss <img class="math" src="_images/math/2a7774260eb6b9f1633ac518b2d46bdf453db939.png" alt="\ell(w; (x, y)) = \max(0, |w^T x - y| - \epsilon)"/> に対して，パラメータを
<img class="math" src="_images/math/bcfaaa713f967cdd59959432e36cc53aed23f5af.png" alt="w_{t+1} = w_{t} + \{\mathrm{sign}(y - w^Tx) \ell / |x|^2\} x"/> で逐次更新する．</p>
<p>さらに，大きく更新しすぎるのを防ぐために， PA-I 同様のコストを追加する．
オリジナルの PA-I では， <img class="math" src="_images/math/24721711188c24ddb69837efe7b59908d78aac40.png" alt="\ell / |x|^2"/> の代わりに <img class="math" src="_images/math/37a78534c713ec7401b5ec734bc30cc218d53858.png" alt="\min(C, \ell / |x|^2)"/> で更新するが，回帰問題では <img class="math" src="_images/math/fcd3c7d79435a73a909916f6ae106d4b640566e5.png" alt="\ell"/> と <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> のスケールに対して <img class="math" src="_images/math/2bcc65482aa8e15cd4c9e9f2542451fb4e971a91.png" alt="C"/> の調整が難しい．
そこで，  <img class="math" src="_images/math/fcd3c7d79435a73a909916f6ae106d4b640566e5.png" alt="\ell"/> の標準偏差 <img class="math" src="_images/math/2298cf1485084afe72757a9c8483af49a138d81f.png" alt="\sigma"/> をオンラインで計測し， <img class="math" src="_images/math/2bcc65482aa8e15cd4c9e9f2542451fb4e971a91.png" alt="C"/> の値を調整する．
まず，予測値 <img class="math" src="_images/math/08697d3b5494477a24cb97ce5e31a3424b6ca8af.png" alt="w^T x"/> と 実測値 <img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> との差， <img class="math" src="_images/math/f4c7a057f395e5b21b6a896072a08f53666e6fb4.png" alt="e = y - w^T x"/> とする．
<img class="math" src="_images/math/630e3a780577ea7921e81ee2ac5237dd1802ec8d.png" alt="e"/> の平均と二乗の平均の予測値を， <img class="math" src="_images/math/939c04f7cf48ed76de97124880e801199e69cd45.png" alt="s_{t+1} = \alpha s_{t}  + (1-\alpha)e"/> と <img class="math" src="_images/math/6fa9d26b7eff2c8a0db92a39ebe3e32591a9d6a2.png" alt="q_{t+1} = \alpha q_{t} + (1-\alpha)e^2"/> で更新する．
時刻 <img class="math" src="_images/math/ef9270877405055756d345facd044e4ab297f858.png" alt="t"/> での標準偏差を <img class="math" src="_images/math/b3daa0c5cddb4eaef7754433f6f1e54f9782bff0.png" alt="\sigma_t = \sqrt{q_t - s_t^2}"/> で予測する．
実際の更新幅は， <img class="math" src="_images/math/23ed438085f0127b38b7b36cc0230846c43873e0.png" alt="\{\mathrm{sign}(y - w^Tx) \min(C \sigma, \ell) / |x|^2\} x"/> となる．</p>
</div>
<div class="section" id="iterative-parameter-mixture">
<h2>Iterative Parameter Mixture<a class="headerlink" href="#iterative-parameter-mixture" title="Permalink to this headline">¶</a></h2>
<p>分類問題同様，重みベクトルは Iterative Parameter Mixture <a class="reference internal" href="#mcdonald10" id="id4">[McDonald10]</a> <a class="reference internal" href="#mann09" id="id5">[Mann09]</a> で混ぜ合わせる．
これは，各マシンが単独で学習アルゴリズムを動かし，一定時間，あるいは決められた条件ごとに，すべてのマシンの重みを集めて，それらの平均を計算する．
平均ベクトルは再度全てのサーバーに配られて，それを初期値と思って学習を再開する．</p>
<p>もともと分類問題向けのモデル共有方法であるが，線形回帰モデルではモデルパラメータが同じ形をしているので，同様に分散学習させることができる可能性が高い．</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt><strong>PA(PA, PA1, PA2): Passive Aggressive</strong></dt>
<dd><table class="first docutils citation" frame="void" id="crammer03a" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[Crammer03a]</a></td><td>Koby Crammer, Ofer Dekel, Shai Shalev-Shwartz and Yoram Singer, <strong>Online Passive-Aggressive Algorithms</strong>, <em>Proceedings of the Sixteenth Annual Conference on Neural Information Processing Systems (NIPS)</em>, 2003.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="crammer03b" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[Crammer03b]</a></td><td>Koby Crammer and Yoram Singer. <strong>Ultraconservative online algorithms for multiclass problems</strong>. <em>Journal of Machine Learning Research</em>, 2003.</td></tr>
</tbody>
</table>
<table class="last docutils citation" frame="void" id="crammer06" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[Crammer06]</a></td><td>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, Yoram Singer, <strong>Online Passive-Aggressive Algorithms</strong>. <em>Journal of Machine Learning Research</em>, 2006.</td></tr>
</tbody>
</table>
</dd>
<dt><strong>CW:  Confidence Weighted Learning</strong></dt>
<dd><table class="first docutils citation" frame="void" id="dredze08" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Dredze08]</td><td>Mark Dredze, Koby Crammer and Fernando Pereira, <strong>Confidence-Weighted Linear Classification</strong>, <em>Proceedings of the 25th International Conference on Machine Learning (ICML)</em>, 2008</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="crammer08" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Crammer08]</td><td>Koby Crammer, Mark Dredze and Fernando Pereira, <strong>Exact Convex Confidence-Weighted Learning</strong>, <em>Proceedings of the Twenty Second Annual Conference on Neural Information Processing Systems (NIPS)</em>, 2008</td></tr>
</tbody>
</table>
<table class="last docutils citation" frame="void" id="crammer09a" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Crammer09a]</td><td>Koby Crammer, Mark Dredze and Alex Kulesza, <strong>Multi-Class Confidence Weighted Algorithms</strong>, <em>Empirical Methods in Natural Language Processing (EMNLP)</em>, 2009</td></tr>
</tbody>
</table>
</dd>
<dt><strong>AROW: Adaptive Regularization of Weight vectors</strong></dt>
<dd><table class="first last docutils citation" frame="void" id="crammer09b" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Crammer09b]</td><td>Koby Crammer, Alex Kulesza and Mark Dredze, <strong>Adaptive Regularization Of Weight Vectors</strong>, <em>Advances in Neural Information Processing Systems</em>, 2009</td></tr>
</tbody>
</table>
</dd>
<dt><strong>NHERD: Normal Herd</strong></dt>
<dd><table class="first last docutils citation" frame="void" id="crammer10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Crammer10]</td><td>Koby Crammer and Daniel D. Lee, <strong>Learning via Gaussian Herding</strong>, <em>Neural Information Processing Systems (NIPS)</em>, 2010.</td></tr>
</tbody>
</table>
</dd>
<dt><strong>Iterative Parameter Mixture</strong></dt>
<dd><table class="first docutils citation" frame="void" id="mcdonald10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[McDonald10]</a></td><td>Ryan McDonald, K. Hall and G. Mann, <strong>Distributed Training Strategies for the Structured Perceptron</strong>, <em>North American Association for Computational Linguistics (NAACL)</em>, 2010.</td></tr>
</tbody>
</table>
<table class="last docutils citation" frame="void" id="mann09" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[Mann09]</a></td><td>Gideon Mann, R. McDonald, M. Mohri, N. Silberman, and D. Walker, <strong>Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models</strong>, <em>Neural Information Processing Systems (NIPS)</em>, 2009.</td></tr>
</tbody>
</table>
</dd>
</dl>
</div>
</div>
<div class="section" id="recommender">
<h1>Recommender<a class="headerlink" href="#recommender" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id6">
<h2>Overview<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>レコメンダは，類似するデータを推薦したり，データ中の未知の属性を推定することによって推薦するためのモジュールである．</p>
<p>類似データの推薦操作であるsimilar_rowは，行をクエリとし，その行と類似する行を返す．
未知属性の推薦操作であるcomplete_rowは，行をクエリとし，その行の属性値を類似する行の情報を用いて推定する．</p>
</div>
<div class="section" id="data-representation">
<h2>Data Representation<a class="headerlink" href="#data-representation" title="Permalink to this headline">¶</a></h2>
<p>データはrowとcolumnからなる行列で表現される．各データはuniqueなidで紐付けられたrowデータで表される．各rowデータは，column名とそれに紐付く浮動小数点値からなる．但し，全てのcolumn値は指定されていなくても良い．row名，column名はあらかじめ全て指定されていなくても良い．</p>
</div>
<div class="section" id="similarity-calculation">
<h2>Similarity Calculation<a class="headerlink" href="#similarity-calculation" title="Permalink to this headline">¶</a></h2>
<p>rowデータはベクトルで表現され，ベクトル間の類似度はcos類似度，またはJaccard係数で計算される．</p>
<p>列ベクトル <img class="math" src="_images/math/4bee6c8143f58f4fe181c0845298f4bd28cc61e1.png" alt="x, y"/> が与えられたとする．この時，cos類似度は <img class="math" src="_images/math/8f3b0aaa1234cef72eaf212982affda60a496132.png" alt="\cos(x, y) = x^T y / |x||y|"/> と定義される，但し <img class="math" src="_images/math/56e05998ccf720377d259427ffc43d7928b9ba2b.png" alt="|x|"/> はベクトル <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> のノルムである．</p>
<p>Jaccard係数は <img class="math" src="_images/math/05d677e4ed81c6e5925dfbdce4ee4355e0691239.png" alt="Jac(x, y) = |\cap(x, y)| / |\cup(x, y)|"/> として計算される，但し， <img class="math" src="_images/math/67fa4314191ac15d490aba322afb7428a4d4da23.png" alt="\cap(x, y) = \sum_i \min(x_i, y_i), \cup(x, y) = \sum_i \max(x_i, y_i)"/> である．</p>
<p>なお，登録されていない空の値は <img class="math" src="_images/math/74c081db590f3d35421c1f6b9afd4cdda36ee210.png" alt="0"/> として扱われる．</p>
</div>
<div class="section" id="algorithms">
<h2>Algorithms<a class="headerlink" href="#algorithms" title="Permalink to this headline">¶</a></h2>
<div class="section" id="inverted-index">
<h3>inverted_index<a class="headerlink" href="#inverted-index" title="Permalink to this headline">¶</a></h3>
<p>転置インデクスを利用したレコメンダである．転置インデクスは特徴ID毎にそれが発火した特徴データ集合を格納する．これにより類似度に影響がある特徴ID，データだけを列挙できるようになるので，クエリが疎である場合に高速化をはかることができる．</p>
</div>
<div class="section" id="lsh">
<h3>lsh<a class="headerlink" href="#lsh" title="Permalink to this headline">¶</a></h3>
<p>局所近傍ハッシュ (Locality Sensitive Hash, LSH) を利用したレコメンダである．データ毎にそのデータを表すビット列を計算して，ビット列を格納する．データ間のcos類似度は，ビット間のハミング距離から求められる類似度によって計算できる．</p>
<p>ベクトル <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> に対し, <img class="math" src="_images/math/e9203da50e1059455123460d4e716c9c7f440cc3.png" alt="k"/> 個のランダムなベクトル <img class="math" src="_images/math/20b5bb64a21e9657ac70b8ee48965702b745eb38.png" alt="\{a_i\}_{i=1 \cdots k}"/> との内積をとり， <img class="math" src="_images/math/a581f053bbfa5115f42c13094857cdd12a37ec49.png" alt="i"/> 番目のベクトルとの内積値が正であれば， <img class="math" src="_images/math/0962cc8254254113afbc843d581702a799d4e527.png" alt="b_i = 1"/> , そうでなければ <img class="math" src="_images/math/5b86069aa9ef9e2f44a51619d092cee948d0cd10.png" alt="b_i=0"/> となるようなビットベクトルを作成する．このように作成されたビットベクトルを <img class="math" src="_images/math/4a07928e3c372174abd216855837bbed9c920db1.png" alt="lsh(x)"/> とする．また，２つのビットベクトル間 <img class="math" src="_images/math/62de19842e21e76092a457ca882df43cc46953a3.png" alt="a, b"/> で一致したビット数を <img class="math" src="_images/math/efdbaa758fdd9eb2659950267a9a7ca6cf4a1d9d.png" alt="match(a, b)"/> とする時，
<img class="math" src="_images/math/c58b16c932a7fa5ede9a8690814203cbb19fdb5c.png" alt="\cos(x, y) = E(match(lsh(x), lsh(y)))"/> が成り立つ，但し，期待値はランダムなベクトル生成に関してとるとする．</p>
<p>これにより，任意のベクトル間のcos類似度計算は，それらのベクトルから生成されたビットベクトル間のビット一致数により近似できる．元々のベクトルに比べ，ビットベクトルは小さくまた固定長であるため通信容量を大幅に削減することができる他，類似度計算を高速に実現することができる．</p>
</div>
<div class="section" id="minhash">
<h3>minhash<a class="headerlink" href="#minhash" title="Permalink to this headline">¶</a></h3>
<p>MinHashを利用したレコメンダである．各データ毎にそのデータを表すビット列を計算して，ビット列を格納する．データ間のJaccard係数は，ビット間のハミング距離から求められる類似度によって計算できる．</p>
<p>はじめに集合間に対するJaccard係数を説明し，これを実数ベクトル間に対するJaccard係数に拡張する．</p>
<p>前述のように，2つの集合 <img class="math" src="_images/math/b966caeda68b9d033719001cad7c32a215d3c2bb.png" alt="X, Y"/> のJaccard係数を， <img class="math" src="_images/math/8d2f9559b57d2dc33cd98bed7c492041ae721e9d.png" alt="Jac(X, Y) = |\cap(X, Y)|/|\cup(X, Y)|"/> とする．MinHashは適当なハッシュ関数を利用し，集合中の各要素のハッシュ値を求め，その最小値を <img class="math" src="_images/math/c150a089ad77eef63c987e2700183c2da52a3acd.png" alt="m_h(X)"/> とした時， <img class="math" src="_images/math/a5a56e90cf12e44f5dc0283df0808ed675784d74.png" alt="m_h(X) = m_h(Y)"/> となる確率は <img class="math" src="_images/math/4ef9038d59228e78121fb5e1d1b5eaedead2a37c.png" alt="Jac(X, Y)"/> と一致することを利用し，このJaccard係数を推定する．複数のハッシュ関数を用意しそれらの間で一致した割合を求めると，それは <img class="math" src="_images/math/4ef9038d59228e78121fb5e1d1b5eaedead2a37c.png" alt="Jac(X, Y)"/> に近づく．また，実際のハッシュ値を保持せずに，ハッシュ値の最下位のビットのみを記録したとしても，衝突分を差し引くことで，Jaccard係数を求めることができる <a class="reference internal" href="#ping2010" id="id7">[Ping2010]</a> ．今回はこの方法を利用した．</p>
<p>次に各要素が正の実数値を持つ場合に拡張する <img class="math" src="_images/math/67fa4314191ac15d490aba322afb7428a4d4da23.png" alt="\cap(x, y) = \sum_i \min(x_i, y_i), \cup(x, y) = \sum_i \max(x_i, y_i)"/> と定義する．この時，各要素がその値の個数だけ存在するようなハッシュ関数を利用する必要がある．カラム名のハッシュ値を <img class="math" src="_images/math/cbb80ad77aa7a5e227d5a46bc44d235284106cfc.png" alt="h"/> とした時， <img class="math" src="_images/math/6490b6bb976f04f41f7b9f6a1d3bcf597187947e.png" alt="-\log(h) / x_i"/> をこの要素のハッシュ値とする．このハッシュ値で計算された場合，minhash値は一致する．</p>
</div>
<div class="section" id="euclid-lsh">
<h3>euclid_lsh<a class="headerlink" href="#euclid-lsh" title="Permalink to this headline">¶</a></h3>
<p>ユークリッド距離のための局所近傍ハッシュを利用したレコメンダである．複数テーブルを用いた効率的な探索と，cos類似度の局所近傍ハッシュとユークリッドノルム値を用いたリランキングによってユークリッド空間における近傍探索を実現する．</p>
<p>ユークリッド空間における局所近傍ハッシュは <a class="reference internal" href="#datar2004" id="id8">[Datar2004]</a> で提案されたものを用いる．cos類似度の局所近傍ハッシュと同様に <img class="math" src="_images/math/e9203da50e1059455123460d4e716c9c7f440cc3.png" alt="k"/> 個のランダムなベクトルとの内積を取った後，それぞれを適当な幅 <img class="math" src="_images/math/5e87bf41a96deddf6cb485ff530f153f2590e9cc.png" alt="b"/> 以下のランダムな量子化幅で整数値に量子化し，得られた <img class="math" src="_images/math/e9203da50e1059455123460d4e716c9c7f440cc3.png" alt="k"/> 個の整数を <img class="math" src="_images/math/0a5711c7a37994043b2bc3bb374adca232491762.png" alt="L"/> 個に等分して，別々のハッシュテーブルに記録する．探索の際には同様に <img class="math" src="_images/math/e9203da50e1059455123460d4e716c9c7f440cc3.png" alt="k"/> 個の整数を計算し，<img class="math" src="_images/math/0a5711c7a37994043b2bc3bb374adca232491762.png" alt="L"/> 個のハッシュテーブルから表引きを行う．実際には実装上の工夫 <a class="reference internal" href="#andoni2005" id="id9">[Andoni2005]</a> によりこの操作を単一のハッシュテーブルで実現する．また，小さな <img class="math" src="_images/math/0a5711c7a37994043b2bc3bb374adca232491762.png" alt="L"/> に対しても高い再現率を達成するために，各ハッシュ値が１だけ異なるようなエントリーも見るマルチプローブ探索 <a class="reference internal" href="#lv2007" id="id10">[Lv2007]</a> を実装している．</p>
<p><a class="reference internal" href="#datar2004" id="id11">[Datar2004]</a> の手法では得られたデータと入力データとの間のユークリッド距離が得られない．そこでJubatusの実装では，最初に計算した <img class="math" src="_images/math/e9203da50e1059455123460d4e716c9c7f440cc3.png" alt="k"/> 個の内積値を正負でビット化したもの（cos類似度のハッシュ値と同じもの）と元のベクトルのユークリッドノルムも保存しておく．cos類似度のハッシュを用いることで，表引きによって得られたデータ <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> と入力データ <img class="math" src="_images/math/23f1b45408e5b4130c0f940fcbfcec54492cbdcd.png" alt="q"/> の間のcos類似度 <img class="math" src="_images/math/af23d79b7c30a6497967ee32e9bd39510b5c23e6.png" alt="\cos(x, q)"/> が推定できる．さらにそれぞれのユークリッドノルム <img class="math" src="_images/math/058a52f46024a5420fa4a43dda005d091780d775.png" alt="\lVert x\lVert, \lVert q\lVert"/> を用いると，これらの間のユークリッド距離は式 <img class="math" src="_images/math/7c1db32ffc6c6c250907a040946aa1251efa6b0a.png" alt="\lVert x-q\lVert^2=\lVert x\lVert^2+\lVert q\lVert^2-2\cos(x, q)"/> によって計算できる．こうして得られたユークリッド距離の推定値を用いて，表引きして得られたデータ集合をソートし直す．</p>
<p>ユークリッド距離は類似度ではなく距離であり，値が小さくなるほど近いという意味になる．対応する類似度に標準的なものがないため，Jubatusではユークリッド距離に <img class="math" src="_images/math/80d842c5b7aabdb4c23f00d2074915d876e294f2.png" alt="-1"/> を掛けたものを類似度として用いる．</p>
</div>
</div>
<div class="section" id="id12">
<h2>References<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt><strong>minhash: b-Bit Minwise Hash</strong></dt>
<dd><table class="first last docutils citation" frame="void" id="ping2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[Ping2010]</a></td><td>Ping Li, Arnd Christian Konig, <strong>b-Bit Minwise Hashing</strong>, <em>WWW</em>, 2010</td></tr>
</tbody>
</table>
</dd>
<dt><strong>euclid_lsh: Euclidean LSH</strong></dt>
<dd><table class="first docutils citation" frame="void" id="datar2004" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Datar2004]</td><td><em>(<a class="fn-backref" href="#id8">1</a>, <a class="fn-backref" href="#id11">2</a>)</em> Mayur Datar, Nicole Immorlica, Piotr Indyk, Vahab S. Mirokni, <strong>Locality-Sensitive Hashing Scheme Based on p-Stable Distributions</strong>, <em>SCG</em>, 2004.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="andoni2005" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id9">[Andoni2005]</a></td><td>Alex Andoni, <strong>LSH Algorithm and Implementation (E2LSH)</strong>, <a class="reference external" href="http://www.mit.edu/~andoni/LSH/">http://www.mit.edu/~andoni/LSH/</a></td></tr>
</tbody>
</table>
<table class="last docutils citation" frame="void" id="lv2007" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[Lv2007]</a></td><td>Qin Lv, William Josephson, Zhe Wang, Moses Charikar, Kai Li, <strong>Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search</strong>, <em>VLDB</em>, 2007.</td></tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div class="section" id="storage">
<h2>Storage<a class="headerlink" href="#storage" title="Permalink to this headline">¶</a></h2>
<div class="section" id="inverted-index-storage">
<h3>inverted_index_storage<a class="headerlink" href="#inverted-index-storage" title="Permalink to this headline">¶</a></h3>
<p>転置インデクスを格納するインデクスである．inverted_indexで利用される．文字列生成のオーバーヘッドを削減するために内部では，カラムID文字列は整数IDに内部で変換され保存される．</p>
</div>
<div class="section" id="bit-index-stroage">
<h3>bit_index_stroage<a class="headerlink" href="#bit-index-stroage" title="Permalink to this headline">¶</a></h3>
<p>ビット列からなるデータ集合を格納するインデクスである．lshとmin_hashで利用される．ビット間の類似度計算部分はビット操作によって実現され高速である．</p>
</div>
</div>
<div class="section" id="data-distribution">
<h2>Data Distribution<a class="headerlink" href="#data-distribution" title="Permalink to this headline">¶</a></h2>
<p>recommenderでは全ての情報をストレージに格納する．</p>
<p>各データは，そのrow IDに従い，コンシステントハッシング(CHT)を用いて同じIDは必ず同じサーバーに振り分けられるようになっており，IDを含む全ての操作は同じサーバーで処理される．</p>
<p>各ストレージでは，サーバー固有である差分情報と，全サーバーで共有する部分に分けて情報を保持する．前者をdiff，後者をmixedとして以降表す．一般にmixedは全サーバーの情報を保持しているので，diffと比べて大きい．</p>
<p>update_row操作ではdiffのみを更新する．similar_row, complete_row操作では,diffとmixedの両方を参照して操作を行う.もし,diffに情報があるrowであれば，diffの方が情報が新しいのでdiffの情報を採用する．あるIDに関する情報はCHTを利用することで同じサーバーに必ず集められる．</p>
<p>mix操作時には各サーバーからdiffをあつめ,それらを合わせた上で，各サーバーに配り直し,mixedに更新として適用する.そしてdiffを空に初期化する操作を施す．diffを集め始めてから，各サーバーに配り直されるまでの間に各サーバーに施された変更は全て破棄される．この破棄分をバッファを２つ持つなどして対応することは今後の課題である．</p>
<p>inverted_index_storageではdiff, mixedは転置ファイルとなっており，bit_index_storageでは各row毎にbit列を保持する.</p>
</div>
</div>
<div class="section" id="anomaly">
<h1>Anomaly<a class="headerlink" href="#anomaly" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id13">
<h2>References<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt><strong>Local Outlier Factor</strong></dt>
<dd><table class="first last docutils citation" frame="void" id="breunig2000" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Breunig2000]</td><td>Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, Jörg Sander, <strong>LOF: Identifying Density-Based Local Outliers</strong>, SIGMOD, 2000.</td></tr>
</tbody>
</table>
</dd>
</dl>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="rb-modindex.html" title="Ruby Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="api_unlearner.html" title="Unlearner"
             >next</a> |</li>
        <li class="right" >
          <a href="api_weight.html" title="Weight"
             >previous</a> |</li>
        <li><a href="index.html">Jubatus</a> &raquo;</li>
          <li><a href="references.html" >References</a> &raquo;</li>
          <li><a href="api.html" >Client API</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2016 PFN &amp; NTT.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.4.1.
    </div>

    <!-- https://github.com/blog/273-github-ribbons -->
    <a href="http://github.com/jubatus/jubatus">
      <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png" alt="Fork me on GitHub" />
      </a>
  </body>
</html>